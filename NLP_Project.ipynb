{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ja0e9nzrTUIy",
        "XMddbQ-odjc9",
        "_NYyzZAda_fl"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShashankKamath/AutoML/blob/master/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFhdIq_waHyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "02c9fa92-92af-4f44-d48f-644a6363c7e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkhmA6JwWqbR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "e871ec0e-bb03-43e5-f972-b514ac238d69"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from ast import literal_eval\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import re\n",
        "\n",
        "!pip install scikit-surprise\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise.model_selection import cross_validate\n",
        "# from surprise import evaluate\n",
        "\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "os.chdir('/content/drive/My Drive/the-movies-dataset')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/da/b5700d96495fb4f092be497f02492768a3d96a3f4fa2ae7dea46d4081cfa/scikit-surprise-1.1.0.tar.gz (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.17.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.3.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.12.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.0-cp36-cp36m-linux_x86_64.whl size=1678220 sha256=ec9a62511901ce7bdaab1e4cb1ed12f666bede00d390dbc98ff652007effe5b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/fa/8c/16c93fccce688ae1bde7d979ff102f7bee980d9cfeb8641bcf\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTi15f3xS1En",
        "colab_type": "text"
      },
      "source": [
        "## Model 1 - Only Plot Description into consideration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaXjIPzxS0yS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "8f53c2a1-9b01-48d6-ee2c-02a9c68b0128"
      },
      "source": [
        "# path = r'C:/Users/shash/PycharmProjects/Web-Scraping/Faculty Analysis/Dataset'\n",
        "# os.chdir(r'C:\\Users\\shash\\PycharmProjects\\Web-Scraping\\NLP\\Project\\dataset')\n",
        "# Load Movies Metadata\n",
        "metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
        "# metadata['overview'].head()\n",
        "# metadata.shape\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "#Replace NaN with an empty string\n",
        "metadata['overview'] = metadata['overview'].fillna('')\n",
        "\n",
        "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
        "tfidf_matrix = tfidf.fit_transform(metadata['overview'])\n",
        "\n",
        "#Output the shape of tfidf_matrix\n",
        "# print(tfidf_matrix.shape)\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# Compute the cosine similarity matrix\n",
        "#cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "# sim_scores = linear_kernel(tfidf_matrix[idx], tfidf_matrix)\n",
        "#Construct a reverse map of indices and movie titles\n",
        "indices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()\n",
        "# Function that takes in movie title as input and outputs most similar movies\n",
        "\n",
        "def get_recommendations(title):\n",
        "    # Get the index of the movie that matches the title\n",
        "    idx = indices[title]\n",
        "    sim_scores = linear_kernel(tfidf_matrix[idx], tfidf_matrix)\n",
        "    # Get the pairwsie similarity scores of all movies with that movie\n",
        "    #sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "#    sim_scores = sim_scores[0]\n",
        "#    sim_scores.sort()\n",
        "    # Sort the movies based on the similarity scores\n",
        "    sim_scores = list(enumerate(sim_scores[0]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the 10 most similar movies\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # Get the movie indices\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top 10 most similar movies\n",
        "    return metadata['title'].iloc[movie_indices]\n",
        "    # print(recommeded_list)\n",
        "\n",
        "    # for moviename in recommeded_list:\n",
        "    #     print(\"Movie:\",moviename)\n",
        "\n",
        "    #     response = requests.get('https://api.themoviedb.org/3/search/movie?api_key=a6a79866abdec941dc00ef285bc96be3&query=' + moviename)\n",
        "    #     # response = requests.get('https://api.themoviedb.org/3/movie/8844?api_key=a6a79866abdec941dc00ef285bc96be3')\n",
        "    #     result_json=response.json()\n",
        "    #     if len(result_json)>0:\n",
        "    #         if len(result_json['results'])>0:\n",
        "    #             image = requests.get('https://image.tmdb.org/t/p/w185/'+result_json['results'][0]['poster_path'])\n",
        "    #             webbrowser.open_new_tab('https://image.tmdb.org/t/p/w185/'+result_json['results'][0]['poster_path'])\n",
        "    #             # print(image)\n",
        "\n",
        "\n",
        "# get_recommendations('The Dark Knight Rises')\n",
        "\n",
        "print(get_recommendations('The Dark Knight Rises'))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12481                                      The Dark Knight\n",
            "150                                         Batman Forever\n",
            "1328                                        Batman Returns\n",
            "15511                           Batman: Under the Red Hood\n",
            "585                                                 Batman\n",
            "21194    Batman Unmasked: The Psychology of the Dark Kn...\n",
            "9230                    Batman Beyond: Return of the Joker\n",
            "18035                                     Batman: Year One\n",
            "19792              Batman: The Dark Knight Returns, Part 1\n",
            "3095                          Batman: Mask of the Phantasm\n",
            "Name: title, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja0e9nzrTUIy",
        "colab_type": "text"
      },
      "source": [
        "## Model 2 - Combining the cast, director, keywords, and plot "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdRmno_0Tbn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "credits = pd.read_csv(\"credits.csv\")\n",
        "keywords = pd.read_csv(\"keywords.csv\")\n",
        "metadata = pd.read_csv('movies_metadata.csv')\n",
        "\n",
        "metadata = metadata.drop([19730, 29503, 35587])\n",
        "\n",
        "keywords['id'] = keywords['id'].astype('int')\n",
        "credits['id'] = credits['id'].astype('int')\n",
        "metadata['id'] = metadata['id'].astype('int')\n",
        "\n",
        "# Merging the datasets\n",
        "metadata = metadata.merge(credits, on=\"id\")\n",
        "metadata = metadata.merge(keywords, on=\"id\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyYupp_CRofm",
        "colab_type": "text"
      },
      "source": [
        "Reducing the dataset size because of memory error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ217I8ZRk-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# C = metadata_1['vote_average'].mean()\n",
        "# m = metadata_1['vote_count'].quantile(0.90)\n",
        "# metadata = metadata_1.copy().loc[metadata_1['vote_count'] >= m]\n",
        "# metadata.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzLcKJ0wV7FU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metadata['cast'] = metadata['cast'].apply(literal_eval)\n",
        "metadata['crew'] = metadata['crew'].apply(literal_eval)\n",
        "metadata['genres'] = metadata['genres'].apply(literal_eval)\n",
        "metadata['keywords'] = metadata['keywords'].apply(literal_eval)\n",
        "# metadata['cast_size'] = metadata['cast'].apply(lambda x: len(x))\n",
        "# metadata['crew_size'] = metadata['crew'].apply(lambda x: len(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsxy-wzpWRM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_director(x):\n",
        "  for i in x:\n",
        "      if i['job'] == 'Director':\n",
        "          return i['name']\n",
        "  return np.nan\n",
        "metadata['director'] = metadata['crew'].apply(get_director)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuaOe691ImkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns the list top 3 elements or entire list; whichever is more.\n",
        "def get_list(x):\n",
        "  if isinstance(x, list):\n",
        "      names = [i['name'] for i in x]\n",
        "      #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
        "      if len(names) > 3:\n",
        "          names = names[:3]\n",
        "      return names\n",
        "\n",
        "  #Return empty list in case of missing/malformed data\n",
        "  return []\n",
        "\n",
        "features = ['cast', 'keywords', 'genres']\n",
        "for feature in features:\n",
        "    metadata[feature] = metadata[feature].apply(get_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yd9YYBHKNtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to convert all strings to lower case and strip names of spaces\n",
        "def clean_data(x):\n",
        "  if isinstance(x, list):\n",
        "      return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
        "  else:\n",
        "      #Check if director exists. If not, return empty string\n",
        "      if isinstance(x, str):\n",
        "          return str.lower(x.replace(\" \", \"\"))\n",
        "      else:\n",
        "          return ''\n",
        "\n",
        "features = ['cast','director', 'genres']\n",
        "\n",
        "for feature in features:\n",
        "    metadata[feature] = metadata[feature].apply(clean_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2r9pZBvXlyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = metadata.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\n",
        "s.name = 'keyword'\n",
        "s=s.value_counts()\n",
        "s = s[s > 1]\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "\n",
        "def filter_keywords(x):\n",
        "  words = []\n",
        "  for i in x:\n",
        "      if i in s:\n",
        "          words.append(i)\n",
        "  return words\n",
        "\n",
        "metadata['keywords'] = metadata['keywords'].apply(filter_keywords)\n",
        "metadata['keywords'] = metadata['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
        "metadata['keywords'] = metadata['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtsyGhDfLHiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scrub_words(text):\n",
        "  \"\"\"Basic cleaning of texts.\"\"\"\n",
        "  \n",
        "  # remove html markup\n",
        "  text=re.sub(\"(<.*?>)\",\"\",text)\n",
        "  \n",
        "  #remove non-ascii and digits\n",
        "  text=re.sub(\"(\\\\W|\\\\d)\",\" \",text)\n",
        "  \n",
        "  #remove whitespace\n",
        "  text=text.strip()\n",
        "  return text\n",
        "\n",
        "metadata['overview'] = metadata['overview'].fillna('')\n",
        "metadata['overview'] = metadata['overview'].apply(scrub_words)\n",
        "#Stemming the overview\n",
        "stemmer = SnowballStemmer('english')\n",
        "metadata['overview'] = metadata['overview'].apply(stemmer.stem)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLc7P9gmIz0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# metadata[['title', 'cast', 'director', 'keywords', 'genres','overview']].head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwzshBgEOjxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Can add title and tagline as well\n",
        "def create_soup(x):\n",
        "  return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres']) + x['overview'] #+ x['title']\n",
        "metadata['soup'] = metadata.apply(create_soup, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62UQJ8FTKhZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import CountVectorizer and create the count matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0,stop_words='english')\n",
        "count_matrix = count.fit_transform(metadata['soup'])\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "metadata = metadata.reset_index()\n",
        "indices = pd.Series(metadata.index, index=metadata['title'])\n",
        "\n",
        "\n",
        "def get_recommendations(title,indices):\n",
        "  idx = indices[title]\n",
        "  sim_scores = cosine_similarity(count_matrix[idx], count_matrix)\n",
        "  sim_scores = list(enumerate(sim_scores[0]))\n",
        "\n",
        "  # Sort the movies based on the similarity scores\n",
        "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # Get the scores of the 10 most similar movies\n",
        "  sim_scores = sim_scores[1:11]\n",
        "\n",
        "  # Get the movie indices\n",
        "  movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "  # Return the top 10 most similar movies\n",
        "  return metadata['title'].iloc[movie_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX26cmL8YeMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ed15e8b8-6d9f-4c4d-fcd1-3be7bad01b32"
      },
      "source": [
        "print(get_recommendations('The Dark Knight Rises', indices, cosine_sim2))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12589                            The Dark Knight\n",
            "150                               Batman Forever\n",
            "10210                              Batman Begins\n",
            "585                                       Batman\n",
            "18225                           Batman: Year One\n",
            "1349                              Batman Returns\n",
            "15682                 Batman: Under the Red Hood\n",
            "19981    Batman: The Dark Knight Returns, Part 1\n",
            "1511                              Batman & Robin\n",
            "43147                      DC Showcase: Catwoman\n",
            "Name: title, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHyWp9DhWjKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# metadata['cast'] = metadata['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
        "# metadata['cast'] = metadata['cast'].apply(lambda x: x[:3] if len(x) >=3 else x)\n",
        "# metadata['cast'] = metadata['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
        "# metadata['keywords'] = metadata['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
        "# metadata['director'] = metadata['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
        "# metadata['director'] = metadata['director'].apply(lambda x: [x,x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSh8a5bdXAbT",
        "colab_type": "code",
        "outputId": "3e5dd95b-7673-4bdc-a967-309ff9613bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# metadata['soup'] = metadata['keywords'] + metadata['cast'] + metadata['director'] + metadata['genres'] + metadata['overview']\n",
        "# metadata['soup'] = metadata['soup'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
        "# count_matrix = count.fit_transform(metadata['soup'])\n",
        "\n",
        "# cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
        "\n",
        "# metadata = metadata.reset_index()\n",
        "# titles = metadata['title']\n",
        "# indices = pd.Series(metadata.index, index=metadata['title'])\n",
        "\n",
        "# def get_recommendations(title):\n",
        "#     idx = indices[title]\n",
        "#     sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "#     sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "#     sim_scores = sim_scores[1:31]\n",
        "#     movie_indices = [i[0] for i in sim_scores]\n",
        "#     return titles.iloc[movie_indices]\n",
        "\n",
        "# get_recommendations('The Dark Knight Rises').head(10)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3174         The Dark Knight Rises\n",
              "1984                 Batman Begins\n",
              "47                  Batman Forever\n",
              "3671              Reasonable Doubt\n",
              "3141              Batman: Year One\n",
              "2593      Mesrine: Killer Instinct\n",
              "185                         Batman\n",
              "2209                  The Prestige\n",
              "2730           Law Abiding Citizen\n",
              "2880    Batman: Under the Red Hood\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBgvcJqGS70K",
        "colab_type": "text"
      },
      "source": [
        "## Model 3 - Hybrid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF_4fz9oS98m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "0dcdef74-a676-4dd5-d644-f500102c5401"
      },
      "source": [
        "reader = Reader()\n",
        "ratings = pd.read_csv('ratings_small.csv')\n",
        "\n",
        "#To have same split every time for testing\n",
        "import random\n",
        "random.seed(1)\n",
        "\n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "svd = SVD()\n",
        "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.8968  0.8939  0.8934  0.9008  0.8985  0.8967  0.0028  \n",
            "MAE (testset)     0.6901  0.6860  0.6891  0.6932  0.6929  0.6903  0.0026  \n",
            "Fit time          4.59    4.52    4.62    4.61    4.54    4.58    0.04    \n",
            "Test time         0.15    0.18    0.15    0.16    0.15    0.16    0.01    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (4.5949084758758545,\n",
              "  4.517142295837402,\n",
              "  4.617350101470947,\n",
              "  4.609635829925537,\n",
              "  4.540955543518066),\n",
              " 'test_mae': array([0.69009113, 0.68603977, 0.68905818, 0.69319   , 0.69291543]),\n",
              " 'test_rmse': array([0.89681431, 0.89392165, 0.89337275, 0.90083335, 0.89848737]),\n",
              " 'test_time': (0.1543419361114502,\n",
              "  0.17890191078186035,\n",
              "  0.15398502349853516,\n",
              "  0.1576061248779297,\n",
              "  0.15300250053405762)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaNwfimjbZrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import seaborn library\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "sns.set(font_scale=1.5)\n",
        "%matplotlib inline\n",
        "\n",
        "# Display distribution of rating\n",
        "sns.distplot(ratings['rating'].fillna(ratings['rating'].median()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZQD5RXMXZze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_int(x):\n",
        "  try:\n",
        "    return int(x)\n",
        "  except:\n",
        "    return np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN244LXDXchJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_map = pd.read_csv('links_small.csv')[['movieId', 'tmdbId']]\n",
        "id_map['tmdbId'] = id_map['tmdbId'].apply(convert_int)\n",
        "id_map.columns = ['movieId', 'id']\n",
        "id_map = id_map.merge(metadata[['title', 'id']], on='id').set_index('title')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c08SI_U4XmFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices_map = id_map.set_index('id')\n",
        "metadata = metadata.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkuJpaNGp-ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted_rating(x):\n",
        "    v = x['vote_count']\n",
        "    R = x['vote_average']\n",
        "    return (v/(v+m) * R) + (m/(m+v) * C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O4ClcMOXpU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_index(x):\n",
        "  if x in indices_map:\n",
        "    return svd.predict(userId, indices_map.loc[x]['movieId']).est\n",
        "  else: \n",
        "    pass\n",
        "\n",
        "def hybrid(userId, title):\n",
        "  idx = indices[title]\n",
        "  # tmdbId = id_map.loc[title]['id']\n",
        "  #print(idx)\n",
        "  movie_id = id_map.loc[title]['movieId']\n",
        "  \n",
        "  sim_scores = cosine_similarity(count_matrix[idx], count_matrix)\n",
        "  sim_scores = list(enumerate(sim_scores[0]))\n",
        "  # sim_scores = list(enumerate(cosine_sim[int(idx)]))\n",
        "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "  sim_scores = sim_scores[1:26]\n",
        "  movie_indices = [i[0] for i in sim_scores]\n",
        "  # print(movie_indices)\n",
        "\n",
        "  movies = metadata.iloc[movie_indices][['title', 'vote_count', 'vote_average', 'id']]\n",
        "  # print(movies.head(50))\n",
        "\n",
        "  # vote_counts = movies[movies['vote_count'].notnull()]['vote_count'].astype('int')\n",
        "  # vote_averages = movies[movies['vote_average'].notnull()]['vote_average'].astype('int')\n",
        "  # C = vote_averages.mean()\n",
        "  # m = vote_counts.quantile(0.60)\n",
        "  # qualified = movies[(movies['vote_count'] >= m) & (movies['vote_count'].notnull()) & (movies['vote_average'].notnull())]\n",
        "  # qualified['vote_count'] = qualified['vote_count'].astype('int')\n",
        "  # qualified['vote_average'] = qualified['vote_average'].astype('int')\n",
        "  # qualified['wr'] = qualified.apply(weighted_rating, axis=1)\n",
        "  # qualified = qualified.sort_values('wr', ascending=False).head(25)\n",
        "  \n",
        "  movies['est'] = movies['id'].apply(check_index)\n",
        "  # movies['est'] = movies['id'].apply(lambda x: svd.predict(userId, indices_map.loc[x]['movieId']).est)\n",
        "  movies = movies.sort_values('est', ascending=False)\n",
        "  return movies.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxBPP_7YXz2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "381bf71d-4b47-46e0-b9ee-2e8ce028e202"
      },
      "source": [
        "hybrid(1, 'The Dark Knight')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>id</th>\n",
              "      <th>est</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18442</th>\n",
              "      <td>The Dark Knight Rises</td>\n",
              "      <td>9263.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>49026</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10210</th>\n",
              "      <td>Batman Begins</td>\n",
              "      <td>7511.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>272</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>Batman Forever</td>\n",
              "      <td>1529.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>414</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35011</th>\n",
              "      <td>İtirazım Var</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>265351</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25575</th>\n",
              "      <td>Gangsters</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78566</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32471</th>\n",
              "      <td>Joni</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>124523</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6111</th>\n",
              "      <td>Q &amp; A</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6.6</td>\n",
              "      <td>31598</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24066</th>\n",
              "      <td>In Order of Disappearance</td>\n",
              "      <td>142.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>252822</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30092</th>\n",
              "      <td>Accused</td>\n",
              "      <td>30.0</td>\n",
              "      <td>6.6</td>\n",
              "      <td>242065</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5464</th>\n",
              "      <td>Love Me Tender</td>\n",
              "      <td>21.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>39833</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           title  vote_count  vote_average      id   est\n",
              "18442      The Dark Knight Rises      9263.0           7.6   49026  None\n",
              "10210              Batman Begins      7511.0           7.5     272  None\n",
              "150               Batman Forever      1529.0           5.2     414  None\n",
              "35011               İtirazım Var         9.0           7.1  265351  None\n",
              "25575                  Gangsters         0.0           0.0   78566  None\n",
              "32471                       Joni         0.0           0.0  124523  None\n",
              "6111                       Q & A        22.0           6.6   31598  None\n",
              "24066  In Order of Disappearance       142.0           7.0  252822  None\n",
              "30092                    Accused        30.0           6.6  242065  None\n",
              "5464              Love Me Tender        21.0           5.5   39833  None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OES9xLRcXu38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "12b5f62e-6bae-41d6-a3f6-f93d815ec42d"
      },
      "source": [
        "hybrid(500, 'The Dark Knight Rises')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>id</th>\n",
              "      <th>est</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12589</th>\n",
              "      <td>The Dark Knight</td>\n",
              "      <td>12269.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>155</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>Batman Forever</td>\n",
              "      <td>1529.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>414</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10210</th>\n",
              "      <td>Batman Begins</td>\n",
              "      <td>7511.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>272</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>585</th>\n",
              "      <td>Batman</td>\n",
              "      <td>2145.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>268</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18225</th>\n",
              "      <td>Batman: Year One</td>\n",
              "      <td>255.0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>69735</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>Batman Returns</td>\n",
              "      <td>1706.0</td>\n",
              "      <td>6.6</td>\n",
              "      <td>364</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15682</th>\n",
              "      <td>Batman: Under the Red Hood</td>\n",
              "      <td>459.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>40662</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19981</th>\n",
              "      <td>Batman: The Dark Knight Returns, Part 1</td>\n",
              "      <td>410.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>123025</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>Batman &amp; Robin</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>415</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43147</th>\n",
              "      <td>DC Showcase: Catwoman</td>\n",
              "      <td>36.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>76420</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         title  vote_count  ...      id   est\n",
              "12589                          The Dark Knight     12269.0  ...     155  None\n",
              "150                             Batman Forever      1529.0  ...     414  None\n",
              "10210                            Batman Begins      7511.0  ...     272  None\n",
              "585                                     Batman      2145.0  ...     268  None\n",
              "18225                         Batman: Year One       255.0  ...   69735  None\n",
              "1349                            Batman Returns      1706.0  ...     364  None\n",
              "15682               Batman: Under the Red Hood       459.0  ...   40662  None\n",
              "19981  Batman: The Dark Knight Returns, Part 1       410.0  ...  123025  None\n",
              "1511                            Batman & Robin      1447.0  ...     415  None\n",
              "43147                    DC Showcase: Catwoman        36.0  ...   76420  None\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMddbQ-odjc9",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network Approach - Waste\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FRzw-eHdsMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from importlib import reload\n",
        "import torch\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NYyzZAda_fl",
        "colab_type": "text"
      },
      "source": [
        "### Tf-IDF generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4gvnUmybFA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "faca0c55-a4ac-4ba5-f7cd-3643fb0dfb8b"
      },
      "source": [
        "ratings = pd.read_csv('ratings_small.csv')\n",
        "ratings = ratings.drop_duplicates('movieId')\n",
        "print(\"{} unique movies in ratings.csv\".format(len(ratings.movieId.unique())))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9066 unique movies in ratings.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xys_w09DdpRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(\n",
        "    ngram_range=(0, 1),\n",
        "    min_df=0.0001,\n",
        "    stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(metadata['soup'])\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=metadata.index.tolist())\n",
        "# print(tfidf_df.shape)\n",
        "# tfidf_df.to_pickle('tfidf_matrix.pkl')\n",
        "# tfidf_df.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE6sQQplabPi",
        "colab_type": "text"
      },
      "source": [
        "### Auto Encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31PiEXDEaXEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from autoencoder import AutoEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF_Ct8rdpy5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ae = AutoEncoder(tfidf_df, validation_perc=0.1, lr=1e-3, intermediate_size=5000, encoded_size=100)\n",
        "ae.train_loop(30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIfebO7zp2-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = pd.DataFrame(data=list(zip(ae.train_losses, ae.val_losses)), columns=['train_loss', 'validation_loss'])\n",
        "losses['epoch'] = (losses.index + 1) / 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RANdRenp3uR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%config InlineBackend.figure_format = 'svg'\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(losses['epoch'], losses['train_loss'])\n",
        "ax.plot(losses['epoch'], losses['validation_loss'])\n",
        "ax.set_ylabel('MSE loss')\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_title('autoencoder loss over time')\n",
        "ax.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USqWBFCfp66-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = ae.get_encoded_representations()\n",
        "with open('autoencoder_embeddings.pkl', 'wb') as fh:\n",
        "    pickle.dump(encoded, fh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxhYnBcOZKN4",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSmn8t3ieyu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "credits = pd.read_csv(\"credits.csv\")\n",
        "keywords = pd.read_csv(\"keywords.csv\")\n",
        "metadata = pd.read_csv('movies_metadata.csv')\n",
        "\n",
        "metadata = metadata.drop([19730, 29503, 35587])\n",
        "\n",
        "keywords['id'] = keywords['id'].astype('int')\n",
        "credits['id'] = credits['id'].astype('int')\n",
        "metadata['id'] = metadata['id'].astype('int')\n",
        "\n",
        "# Merging the datasets\n",
        "metadata = metadata.merge(credits, on=\"id\")\n",
        "metadata = metadata.merge(keywords, on=\"id\")\n",
        "\n",
        "metadata['cast'] = metadata['cast'].apply(literal_eval)\n",
        "metadata['crew'] = metadata['crew'].apply(literal_eval)\n",
        "metadata['genres'] = metadata['genres'].apply(literal_eval)\n",
        "metadata['keywords'] = metadata['keywords'].apply(literal_eval)\n",
        "\n",
        "def get_director(x):\n",
        "  for i in x:\n",
        "      if i['job'] == 'Director':\n",
        "          return i['name']\n",
        "  return np.nan\n",
        "metadata['director'] = metadata['crew'].apply(get_director)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmzorcP2fEqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns the list top 3 elements or entire list; whichever is more.\n",
        "def get_list(x):\n",
        "  if isinstance(x, list):\n",
        "      names = [i['name'] for i in x]\n",
        "      #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
        "      if len(names) > 3:\n",
        "          names = names[:3]\n",
        "      return names\n",
        "\n",
        "  #Return empty list in case of missing/malformed data\n",
        "  return []\n",
        "\n",
        "features = ['cast', 'keywords', 'genres']\n",
        "for feature in features:\n",
        "    metadata[feature] = metadata[feature].apply(get_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUL9GsMLfFTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to convert all strings to lower case and strip names of spaces\n",
        "def clean_data(x):\n",
        "  if isinstance(x, list):\n",
        "      return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
        "  else:\n",
        "      #Check if director exists. If not, return empty string\n",
        "      if isinstance(x, str):\n",
        "          return str.lower(x.replace(\" \", \"\"))\n",
        "      else:\n",
        "          return ''\n",
        "\n",
        "features = ['cast','director', 'genres']\n",
        "\n",
        "for feature in features:\n",
        "    metadata[feature] = metadata[feature].apply(clean_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH1muIIgfMt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = metadata.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\n",
        "s.name = 'keyword'\n",
        "s=s.value_counts()\n",
        "s = s[s > 1]\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "\n",
        "def filter_keywords(x):\n",
        "  words = []\n",
        "  for i in x:\n",
        "      if i in s:\n",
        "          words.append(i)\n",
        "  return words\n",
        "\n",
        "metadata['keywords'] = metadata['keywords'].apply(filter_keywords)\n",
        "metadata['keywords'] = metadata['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
        "metadata['keywords'] = metadata['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAAnq3u5fQNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scrub_words(text):\n",
        "  \"\"\"Basic cleaning of texts.\"\"\"\n",
        "  \n",
        "  # remove html markup\n",
        "  text=re.sub(\"(<.*?>)\",\"\",text)\n",
        "  \n",
        "  #remove non-ascii and digits\n",
        "  text=re.sub(\"(\\\\W|\\\\d)\",\" \",text)\n",
        "  \n",
        "  #remove whitespace\n",
        "  text=text.strip()\n",
        "  return text\n",
        "\n",
        "metadata['overview'] = metadata['overview'].fillna('')\n",
        "metadata['overview'] = metadata['overview'].apply(scrub_words)\n",
        "#Stemming the overview\n",
        "stemmer = SnowballStemmer('english')\n",
        "metadata['overview'] = metadata['overview'].apply(stemmer.stem)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIiQawArgxqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "metadata['tagline'] = metadata['tagline'].fillna('')\n",
        "metadata['title'] = metadata['title'].fillna('')\n",
        "def clean_tag_title(text):\n",
        "  text=text.strip()\n",
        "  text=text.lower()\n",
        "  text = text.translate(string.punctuation)\n",
        "  return text\n",
        "metadata['tagline'] = metadata['tagline'].apply(clean_tag_title)\n",
        "# metadata['title'] = metadata['title'].apply(clean_tag_title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjl8QmurfT5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Can add title and tagline as well\n",
        "def create_soup(x):\n",
        "  return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres']) +' '+ x['overview'] + ' ' + x['title'] +' '+ x['tagline']\n",
        "metadata['soup'] = metadata.apply(create_soup, axis=1)\n",
        "\n",
        "def clean_soup(text):\n",
        "  text=text.strip()\n",
        "  text=text.lower()\n",
        "  text = text.translate(string.punctuation)\n",
        "  return text\n",
        "metadata['soup'] = metadata['soup'].apply(clean_soup)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tdNImYmjYvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "0d2e800b-383a-42ef-b3b5-87c9d865406b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "def apply_token(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  result = [i for i in tokens if not i in stop_words]\n",
        "  return result\n",
        "metadata['soup'] = metadata['soup'].apply(apply_token)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXuvaTgJZZU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "class TfidfEmbeddingVectorizer(object):\n",
        "  def __init__(self, word2vec):\n",
        "    self.word2vec = word2vec\n",
        "    self.word2weight = None\n",
        "    if len(word2vec)>0:\n",
        "        self.dim=len(word2vec[next(iter(w2v))])\n",
        "    else:\n",
        "        self.dim=0\n",
        "      \n",
        "  def fit(self, X, y):\n",
        "    tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
        "    tfidf.fit(X)\n",
        "    # if a word was never seen - it must be at least as infrequent\n",
        "    # as any of the known words - so the default idf is the max of \n",
        "    # known idf's\n",
        "    max_idf = max(tfidf.idf_)\n",
        "    self.word2weight = defaultdict(lambda: max_idf, [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X):\n",
        "    return np.array([np.mean([self.word2vec[w] * self.word2weight[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0) for words in X])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1au_1SR6d5Ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "# let X be a list of tokenized texts (i.e. list of lists of tokens)\n",
        "X = metadata['soup'].tolist()\n",
        "model = gensim.models.Word2Vec(X, size=100)\n",
        "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xSf9lJndWj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = TfidfEmbeddingVectorizer(w2v)\n",
        "count = count.fit(metadata['soup'],None)\n",
        "count_matrix = count.transform(metadata['soup'])\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "metadata = metadata.reset_index()\n",
        "indices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xay-91Jnk5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_recommendations(title):\n",
        "  # title=title.lower()\n",
        "  idx = indices[title]\n",
        "  print(\"Movie Index\",idx)\n",
        "  sim_scores = cosine_similarity(count_matrix[idx].reshape(1,-1), count_matrix)\n",
        "  sim_scores = list(enumerate(sim_scores[0]))\n",
        "\n",
        "  # Sort the movies based on the similarity scores\n",
        "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # Get the scores of the 10 most similar movies\n",
        "  sim_scores = sim_scores[1:11]\n",
        "\n",
        "  # Get the movie indices\n",
        "  movie_indices = [i[0] for i in sim_scores]\n",
        "  print(movie_indices)\n",
        "\n",
        "  # Return the top 10 most similar movies\n",
        "  return metadata['title'].iloc[movie_indices],metadata['poster_path'].iloc[movie_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js2-oAxOniwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "bf7492df-5a34-48ad-a977-53ada9ba6b77"
      },
      "source": [
        "idx = indices['The Dark Knight'].iloc[0]\n",
        "print(idx)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJZ74PU0lTv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "1dd715db-1bec-4fe4-9d23-93510fcddef3"
      },
      "source": [
        "a,b = get_recommendations('The Dark Knight')\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Movie Index 12589\n",
            "[26629, 8122, 28208, 20476, 8914, 5409, 18442, 41288, 8897, 10438]\n",
            "26629                             Wicked Blood\n",
            "8122     Sherlock Holmes and the Secret Weapon\n",
            "28208             The Three Fantastic Supermen\n",
            "20476                              Broken City\n",
            "8914                          The Star Chamber\n",
            "5409                            Modesty Blaise\n",
            "18442                    The Dark Knight Rises\n",
            "41288                                   Race 2\n",
            "8897                              Blue Thunder\n",
            "10438                     Revenge of the Ninja\n",
            "Name: title, dtype: object\n",
            "26629    /1wbeqDYxZDmm2Gdg3vDdKiJFi00.jpg\n",
            "8122     /mJyEiDQrxsHlH6oQPeZy4MQ78Rm.jpg\n",
            "28208    /iz9uLv2meeYmcQO0KkoA0jI1wu6.jpg\n",
            "20476    /pYDj2b15p4YdNz88XvO7QmBoHgD.jpg\n",
            "8914     /kBXvrwS0gptAVZ8JkVFVylPxJh8.jpg\n",
            "5409     /b6RMnkos9UltmeOb4h6g2xzlpPt.jpg\n",
            "18442    /dEYnvnUfXrqvqeRSqvIEtmzhoA8.jpg\n",
            "41288    /3xXL3VNUNfl6XZQQcTbMLaKirs4.jpg\n",
            "8897     /sdsA2shw0TA81idpx2EafI6FEwN.jpg\n",
            "10438    /hhVQongUUKCSwZG0RqVIRKVnYVE.jpg\n",
            "Name: poster_path, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RALQPmWLndCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuhWhkQBn-Da",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "f19c599a-8c94-48d3-873c-e03091554408"
      },
      "source": [
        "print(get_recommendations('The Dark Knight Rises'))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18442\n",
            "[12589, 26629, 8221, 437, 18863, 1920, 28783, 4112, 13114, 11123]\n",
            "12589                                    the dark knight\n",
            "26629                                       wicked blood\n",
            "8221               sky captain and the world of tomorrow\n",
            "437                                       demolition man\n",
            "18863                            mr. moto's last warning\n",
            "1920                                       soylent green\n",
            "28783    ghost in the shell arise - border 1: ghost pain\n",
            "4112                                   death on the nile\n",
            "13114                                          max payne\n",
            "11123                                      hollow man ii\n",
            "Name: title, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}